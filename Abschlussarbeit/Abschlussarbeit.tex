\documentclass[11pt]{scrreprt}
\parindent 0pt
\parskip 11pt

\usepackage[latin1]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[colorlinks=false,pdfborder={0 0 0}]{hyperref}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{mathtools}
\DeclareGraphicsExtensions{.png}

\begin{document}

\pagenumbering{Roman}
\tableofcontents

\chapter{Einleitung}
\pagenumbering{arabic}

In der heutigen Zeit haben sich viele elektronische Unterhaltungsmedien
entwickelt und sind im Alltag nicht mehr wegzudenken. Filme, Musik und vor
allem Spiele werden in größerem Ausmaß konsumiert als je zuvor.

Besonders die Computerspielindustrie hat in den letzten Jahren eine Entwicklung
durchgemacht, wie in keinem Industriezweig vor ihr. Der Sprung von wenigen Pixeln zu 
aufwendigen 3D-Grafiken wurde in weniger als einem Jahrzehnt vollzogen und die Zukunft 
bietet immer interessantere Möglichkeiten.

3D-Echtzeit ist das bestimmende Thema in der aktuellen Spieleentwicklung.
Umwerfende Bilder und Effekte werden mit Hilfe von aktueller Hardware generiert
und in flüssigen Bildfolgen zur Verfügung gestellt. Der Spieler taucht geradezu
ein in diese virtuelle Realität, da sich die echte und die virtuelle Welt kaum 
mehr voneinander unterscheiden.

Um diese Tiefe in einem Spiel zu erreichen werden aufwendige Engines entwickelt,
die aus mehreren Bereichen zusammengesetzt sind. Zum einen der visuelle Anteil,
aber auch wichtige Funktionen wie Physik und Sounduntermalung. Wie der Name schon 
suggeriert, sind Spieleengines komplexe Programme, die oft aus tausenden Zeilen von 
Code bestehen und meist in größeren Teams entwickelt werden.

Im Laufe der Zeit wurden die implementierten Algorithmen immer komplexer und mit
ihnen die Möglichkeiten, die eine aktuelle Engine zur Verfügung stellt. Licht,
sowie Schattenwurf und auch verschiedene optische Effekte, wie Bewegungs- bzw.
Tiefenunschärfe sind nur Bruchteile dessen was mit heutiger 3D-Technologie
simuliert werden kann.

Im Wandel befindet sich vor allem die Hardware, die mit der Menge an zu
verarbeitenden Daten fertig werden muss. Grafikkarten sind eigene Rechenwerke,
die Milliarden von Transistoren besitzen und selbst Computer von vor wenigen
Jahren in Bezug auf Rechenleistung ohne Probleme schlagen können.

Diese Leistung ist in den heutigen Grafikanwendungen auch nötig, da in einer
Szene schon gut und gerne mehrere Millionen Polygone gleichzeitig dargestellt
werden müssen. Hinzu kommen noch die eingesetzten Post-Processing Effekte, die
das Bild nachhaltig aufwerten. Selbst die komplexe Physikberechnung wird auf
Grafikkarten ausgelagert, wobei vor kurzem noch die CPU für diese Art von
Berechnung zuständig war.

\section{Motivation}

Die Arbeit beleuchtet einen besonderen Aspekt in der 3D-Echtzeitberechnung, das
Portal Rendering bzw. Portal Culling. Innerhalb der Arbeit werden die
verschiedenen Anwendungsmöglichkeiten dieser Technik dargelegt und mit
Beispielen fundiert.

Als Basis dieser Arbeit dient das jVR-Framework, welches um die Funktionen des
Portal Cullings erweitert wird. Dies ermöglicht den Aufbau von komplexeren
Szenen mit einem geringeren Rechenaufwand, da im Verlauf der Erweiterung
Techniken eingesetzt werden um unnötige Objekte vom Rendern auszuschließen.

\section{Aufbau der Arbeit}

\chapter{Aufgabenstellung}

\chapter{Stand der Technik}

\section{Portal Culling}

Portal Culling ist ein Verfahren, um die Leistung in 3D-Echtzeitberechnungen zu
steigern. In diesem Verfahren werden bestimmte Objekte ausgewählt, die
letztendlich gerendert werden und damit für den Betrachter sichtbar werden.

Beim Portal Culling stellt man sich einen Bereich vor, der aus mehreren Zellen
besteht. Eine Zelle setzt sich aus mehreren Wänden zusammen und kann an weitere
Zellen angrenzen. Diese Zellen verbinden einander durch Türen bzw. Fenster, so
genannte Portale. Portale sind in der Regel durchsichtig und können in den
meisten Fällen auch betreten werden.

Dadurch lassen sich große Szenen erstellen, die innerhalb eines Gebäudes oder
eines Tunnelsystems spielen. Die Komplexität lässt sich beliebig skalieren, da
sich beliebig viele Zellen miteinander verbinden lassen.

Der Sinn des Portal Cullings besteht darin, Objekte innerhalb der
verschiedenen Zellen zu rendern bzw. nicht zu rendern je nach Sichtbarkeit des
jeweiligen Objektes. Wird z.B. ein Objekt durch eine Wand verdeckt, besteht
keine Notwendigkeit das Objekt zu rendern und es wird zudem Rechenzeit
gespart. Durch den Einsatz dieses Verfahrens können bis zu 50 Prozent der
benötigten Ressourcen zum Rendern eingespart werden.

% \begin{figure}[h]
% \begin{center}
% \includegraphics[height=50mm]{img/portalsplate1}
% \end{center}
% \caption{Test 1234}
% \end{figure}

Zellen können auch ganz vom Renderprozess ausgeschlossen werden. Dies geschieht,
wenn das Portal, das zur nächsten Zelle führt außerhalb des Sichtbereiches
liegt. Dadurch wird die komplette Zelle und alle enthaltenen Objekte nicht
gerendert.

Der erste Portal Culling Algorithmus wurde 1990 von Airey vorgestellt. Im
späteren Verlauf wurden von \cite{visComp} bzw. \cite{visAlgo}
verbesserte komplexere und vor allem effizientere Algorithmen zum Thema Portal
Culling entwickelt.

All diese Algorithmen gleichen sich in der Annahme, dass die Wände als
verdeckendes Element für Szenen dienen, die innerhalb eines Raumes stattfinden.
Des Weiteren wird durch jedes Portal ein View Frustum Culling (siehe Frustum
Culling) durchgeführt. Das eigentliche Frustum wird durch das Portal auf dessen
Größe reduziert, somit werden alle Objekte und auch Portale außerhalb des
Sichtbereichs vom Rendern ausgeschlossen. Diese Vorgehensweise kann rekursiv
fortgesetzt werden, falls sich innerhalb des betrachteten Raumes ein weiteres
Portal befindet.

\subsection{Portale als Spiegel}

Ein weiterer Verwendungszweck von Portal Culling ist die Erzeugung von Spiegeln.
Spiegel reflektieren den Sichtbereich des Betrachters. Wenn man aus Sicht des
Spiegels in die Szene schaut und diese nochmals spiegelt, erhält man das Bild
welches der Betrachter bei Blick in den Spiegel erhält. Man nimmt den Spiegel in
diesem Fall als Spiegelebene und erstellt an der gespiegelten Position des
Betrachters eine Kamera. Diese rendert dann die Szene durch den Spiegel. Danach
wird die gerenderte Szene aus Sicht der Spiegelkamera auf den Spiegel
projeziert.

Spiegel werden häufig in Szenen eingesetzt, die eingerichtete Wohnungen oder
Räumlich-keiten repräsentieren sollen. Dadurch bekommt der Betrachter einen
Eindruck davon, wie der Spiegel innerhalb des Raumes wirkt.

In Computerspielen dienen Spiegel oft als Stilmittel, um z.B. die eigene
Spielfigur betrachten zu können (z.b. First-Person Shooter). Oder um
atmosphärische Spannung zu erzeugen, wenn z.B. eine geistähnliche Gestalt im
Spiegel erscheint.

Mit Hilfe von Shadern kann hinzukommend noch eine glasähnliche Oberfläche
simuliert werden, was den Eindruck eines Spiegels nochmals verstärkt. Außerdem
lassen sich zudem noch Materialschäden oder Abnutzungserscheinungen hinzufügen
um den Eindruck von Verschleiß zu erwecken.

\subsection{Portale als Teleporter}

Zudem lassen sich Portale dazu nutzen sich innerhalb der Umgebung zu
teleportieren. Das bedeutet, dass man sich von einem Ort zu einem anderen
Ort in kürzester Zeit bewegt, obwohl diese sehr weit von einander entfernt
liegen. Dazu werden 2 oder auch nur ein Portal erzeugt und der Ausgang des einen
Portals stellt den Frustum des anderen Portals dar. Dabei wird eine Kamera
benutzt die genau den entgegengesetzten Sichtbereich des ersten Portals rendert,
wobei aber der Sichtbereich auf das zweite Portal gerendert wird. Bei
Durchtreten der beiden Portale wird die Position des Betrachters dementsprechend
verändert.

Möglich ist es zudem ein Portal als Einbahnstraße zu benutzen, wodurch der
Betrachter nicht mehr in der Lage ist an die Stelle des durchtretenden Portals
ohne Probleme zurückzukehren. Dies bedeutet, dass der Betrachter zwar von
Stelle 1 nach Stelle 2 teleportiert wird, wenn er das Portal durchtritt, aber
nicht mehr von Stelle 2 an die Stelle 1 gelangen kann, da sich dort kein Portal
befindet. Man erreicht dies, indem man die Szene an der Stelle durch das
Portal rendert, an der der Spieler austreten soll. Daher wird an diese
Stelle mit dem Verhältnis zur Betrachterkamera die Szene gerendert und auf
der Portaloberfläche gerendert. Diese Herangehensweise lässt sich oft in
Computerspielen wiederfinden, um z.B. ein Labyrinth zu erzeugen oder den Spieler
kurz zu desorientieren.

\subsection{Frustum Culling}

Frustum Culling ist ein Verfahren in der Computergrafik um die Performanz beim
Rendern von Szenen zu steigern. Bei diesem Verfahren werden unnötige Objekte vom
Renderprozess ausgeschlossen.

Beim Frustum Culling wird ein Sichtbereich aufgespannt, das so genannte Frustum.
Es wird überprüft welche Objekte sich innerhalb des Frustums befinden und welche
nicht. Befindet sich ein Objekt innerhalb, wird es gerendert. Ist dies nicht der
Fall wird es verworfen.

Es werden geometrische Primitive um ein Objekt gezeichnet, um festzustellen, ob
es sich innerhalb des Frustums befindet. Diese Primitive nennt man Bounding
Boxes (BB). Da die BB größer ist als das eigentliche Objekt, kann es dazu
führen, dass ein Objekt zwar nicht mehr zu sehen ist aber noch mit seiner BB den
Frustum berührt und daher noch gerendert wird.

\subsection{Occlusion Culling}

Ein weiteres Verfahren um die Performanz zu optimieren ist das Occlusin Culling.
Ähnlich dem Frustum Culling werden Objekte bestimmt, die nicht in den
Renderprozess gehören, da nicht sichtbar.

Anders als beim Frustum Culling werden Objekte nicht außerhalb des Frustums
verworfen. Beim Occlusion Culling wird bestimmt, ob ein Objekt von einem anderen
Objekt verdeckt und damit für den Betrachter nicht sichtbar ist. Diese
verdeckenden Objekte werden als Occluder bezeichnet.

Es gibt 2 Ansätze Occlusion Culling durchzuführen. Einmal gibt es den
punktbasierten Ansatz. In diesem wird die Szene aus Sicht des Betrachters bzw.
eines festen Punktes betrachtet. Dabei werden alle Objekte betrachtet und je
nach Sichtbarkeit zum Renderprozess hinzugefügt oder ausgeschlossen. Diese
Vorgehensweise muss bei Bewegung des Punktes wiederholt werden.

Der zweite Methode stellt der zellenbasierte Ansatz dar. Bei dieser
Vorgehensweise wird eine Zelle von einer bestimmten Größe definiert. Danach
werden alle Objekte bestimmt die innerhalb dieser Zelle für den Betrachter nicht
sichtbar sind, da verdeckt. Diese Methode bietet den Vorteil den Vorgang nur
dann zu wiederholen, falls man den Bereich der Zelle verlässt.

\section{jVR-Framework}
% TODO: besser formulieren, jVR wurde nicht von mir ausgewählt, ist Teil der
% Arbeit
Wie schon vorangehend erwähnt, spielt der Einsatz des jVR-Frameworks eine
zentrale Rolle dieser Arbeit. Dies lässt sich zum einen dadurch begründen, dass
das Framework schon ein grundlegendes Maß an wichtigen Funktionen bietet, die
nötig sind um 3D-Echtzeit-Anwendungen zu erstellen und zum anderen, da es um
weitere nützliche Funktionen erweitert werden kann um Performance bzw.
Produktivität zu steigern.

Das jVR-Framework ist im Rahmen einer Masterarbeit entstanden. Das Framework
soll den Studenten eine Plattform liefern mit denen sie komplexe
3D-Programme erzeugen können. Außerdem soll es den Studenten ein besseres
Verständnis über die Funktionen von 3D-Engines vermitteln.

\subsection{Szenegraph}

Um die Objekte innerhalb einer 2D bzw. 3D-Szene verwalten zu können, wird in dem
jVR-Framework Verwendung von einem Szenegraphen gemacht. Ein Szenegraph
ist eine baumförmige Datenstruktur. Objekte in einer Szene können zum einen
geometrische Objekte oder Lichtquellen sein. Jedes Objekt in der Szene besitzt
eine eigene Transformation. Es besteht außerdem die Möglichkeit Objekte einer
Szene zu animieren. Dies geschieht, indem man die Transformationen in zeitlichen
Intervallen manipuliert.

Über einen Szenengraph lassen sich außerdem Objekte animieren, die in
hierarchischer Beziehung zueinander stehen. Werden mehrere Objekte in einem
Gruppenknoten zusammengefasst entsteht eine hierarchische Beziehung. Dabei kann
der ganze Gruppenknoten transformiert werden, mitsamt den enthaltenen Objekten
oder aber jeder einzelne Objektknoten innerhalb des Gruppenknoten.

\subsubsection{Szeneknoten}

Das jVR-Framework unterscheidet zwischen mehreren Knotentypen. Es gibt zum einen
den schon erwähnten \texttt{GroupNode}. Dieser Knoten kann als einziger
Kinderkoten enthalten. Zusätzlich gibt es noch den \texttt{LightNode}. Dieser
repräsentiert die verschiedenen Lichtquellen und wird von 3 Standardlichtquwllwn
abgeleitet. Diese 3 Lichtquellen sind \texttt{PointLightNode},
\texttt{DirectionalLightNode} und \texttt{SpotLightNode}.

Die \texttt{PointLightNode} strahlt Licht in alle Richtungen gleichzeitig.
Anders hingegen die \texttt{SpotLightNode}, die Licht nur innerhalb eines
gerichteten Kegels ausstrahlt. Die letzte Lichtquelle, die
\texttt{DirectionalLightNode} strahlt Licht parallel in eine bestimmte Richtung.

Die Position des Betrachters wird in der Szene über eine Kamera dargestellt. Der
passende Knotentyp ist die \texttt{CameraNode}. Hinzu kommt die
\texttt{VRCameraNode}, die für den Einsatz in VR-Systemen gedacht ist.

Um geometrische Objekte in einer Szene abzubilden, wird die \texttt{ShapeNode}
genutzt. Einer \texttt{ShapeNode} lassen sich eine Geometrie und ein passendes
Material zuordnen. \texttt{ShapeNodes} lassen sich im Szenegraphen
wiederverwenden. Dazu wird die \texttt{ShapeNode} an verschiedene
\texttt{GroupNodes} gehängt, die unterschiedlich transformiert werden.

Der letzte Knotentyp, über den das jVR-Framework verfügt, ist die
\texttt{ClipPlaneNode}. Sie dient dazu, eine Szene in 2 Halbräume zu unterteilen
und einen der beiden Räume auszublenden.

\subsubsection{Transformationen}

Das jVR-Framework verfügt über mehrere Möglichkeiten Knoten innerhalb einer
Szene zu transformieren. Es werden 5 Arten der Transformation unterschieden.

\begin{align}
\textbf{Transformation:} &
\begin{pmatrix}
\phantom{-\sin \alpha}&\phantom{-\sin \alpha}&\phantom{-\sin
\alpha}&\phantom{-\sin \alpha}\\[-2.5ex] 
1 & 0 & 0 & {t}_{x} \\
0 & 1 & 0 & {t}_{y} \\
0 & 0 & 1 & {t}_{z} \\
0 & 0 & 0 & 1
\end{pmatrix} \\
\textbf{Skalierung:} &
\begin{pmatrix}
\phantom{-\sin \alpha}&\phantom{-\sin \alpha}&\phantom{-\sin
\alpha}&\phantom{-\sin \alpha}\\[-2.5ex]
{s}_{x} & 0 & 0 & 0 \\
0 & {s}_{y} & 0 & 0 \\
0 & 0 & {s}_{z} & 0 \\
0 & 0 & 0 & 0
\end{pmatrix} \\
\textbf{Rotation um X-Achse:} &
\begin{pmatrix}
\phantom{-\sin \alpha}&\phantom{-\sin \alpha}&\phantom{-\sin
\alpha}&\phantom{-\sin \alpha}\\[-2.5ex] 
1 & 0 & 0 & 0 \\
0 & \cos \alpha & -\sin \alpha & 0 \\
0 & \sin \alpha & \cos \alpha & 0 \\
0 & 0 & 0 & 1 
\end{pmatrix} \\
\textbf{Rotation um Y-Achse:} &
\begin{pmatrix}
\phantom{-\sin \alpha}&\phantom{-\sin \alpha}&\phantom{-\sin
\alpha}&\phantom{-\sin \alpha}\\[-2.5ex] 
\cos \beta & 0 & \sin \beta & 0 \\
0 & 1 & 0 & 0 \\
-\sin \beta & 0 & \cos \beta & 0 \\
0 & 0 & 0 & 1
\end{pmatrix} \\
\textbf{Rotation um Z-Achse:} &
\begin{pmatrix}
\phantom{-\sin \alpha}&\phantom{-\sin \alpha}&\phantom{-\sin
\alpha}&\phantom{-\sin \alpha}\\[-2.5ex] 
\cos \gamma & -\sin \gamma & 0 & 0 \\
\sin \gamma & \cos \gamma & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}
\end{align}

\subsubsection{Traversierung}

Um eine baumförmige Datenstruktur wie den Szenegraph zu durchlaufen wird
Gebrauch von der Traversierung gemacht. Dabei werden die einzelnen Knoten der
Szene verarbeitet. Traversierung macht vor allem dann Sinn, wenn z.B.
Szeneknoten mit bestimmten Eigenschaften gesucht werden müssen. Zum Rendern muss
der Szenegraph ebenfalls durchlaufen werden. Angefangen wird dabei beim
Wurzelknoten. Jeder Szeneknoten der an der Wurzel hängt wird in
Welttransformation überführt. Dies geschieht, indem alle Transformationen vom
Wurzelknoten bis zum Szeneknoten multipliziert werden.

\subsection{Drawlisten}

In Drawlisten werden die verschiedenen Szeneknoten mit ihren Weltransformationen
gesammelt und nacheinander gerendert. Eine Drawliste kann zudem beliebig oft
verwendet werden. Das bietet den Vorteil, den Szenegraph nicht nochmals zu
traversieren, falls ein Objekt mehrmals gerendert werden muss.

Nachdem die Drawlisten erstellt wurden, werden sie in der Pipeline gespeichert
und ja nach Bedarf genutzt werden. Das heißt, dass Objekte nach bestimmten
Materialeigenschaften gefiltert und gerendert werden können.

\subsection{Pipelinekonzept}

Die Pipeline im jVR-Framework macht es möglich einzelne Szeneobjekte getrennt
voneinander zu rendern. Man kann zudem verschiedene Materialien zu
Materialklassen zusammenfassen. Materialklassen können wiederum aus mehreren
Shaderkontexten bestehen und somit aus mehreren Shaderprogrammen. 

Shaderkontexte werden größtenteils dafür verwendet Objekte richtig zu
beleuchten. Erst wird mit einem Shaderprogramm die Umgebungsbeleuchtung
(Ambient-Pass) für das Objekt gerendert. Anschließend darauf werden die Objekte
für jede Lichtquelle mit dem Shaderprogramm mit der eigentlichen Beleuchtung
gerendert (Lighting-Pass). Die zuvor erzeugten Bildinformationen werden mittels
des Blending-Verfahrens aufaddiert, (vergleiche auch \cite[S. 46]{jvrMast}).

\subsection{OpenGL}

Für die 3D-Beschleunigung wird die Grafikbibliothek OpenGL verwendet. \emph{Open
Graphics Library}, kurz OpenGL ist ein offener Grafikstandard, der zur
2D- und 3D-Echtzeit-berechnung verwendet wird.

OpenGL geht aus der von Silicon Graphics Inc. (SGI) entwickelten IRIS GL API
hervor. Ab 1992 wurde OpenGL vom OpenGL ARB (Architecture Review Board)
beaufsichtigt und weiterentwickelt. Heute ist die Khronos Group für die
Weiterentwicklung der API zuständig. Die Khronos Group zählt weit über 100
Mitglieder, darunter AMD, Intel und NVIDIA.

OpenGL wird von nahezu jeder Grafikkarte unterstützt, die richtigen Treiber
vorausgesetzt. Die Besonderheit von OpenGL ist im Vergleich zu Direct3D seine
Plattformunabhängigkeit. Ebenso wie Java lässt sich eine Implementation von
OpenGL auf jedem gängigen Betriebssystem, wie Windows, Mac OS X und Linux
finden. Dies erleichtert Programmierern Anwendungen zu erstellen und in
verschiedenen Umgebungen zu testen.

\emph{OpenGL Embedded Systems}, kurz OpenGL ES ist eine spezielle
Zusammenstellung der OpenGL API für mobile Geräte. Dadurch lassen sich
Anwendungen auf mobilen Geräten realisieren. Durch die begrenzten Kapazitäten,
wie Arbeitsspeicher und Rechenleistung der mobilen Hardware, ist diese Version
der OpenGL API um einige Funktionen erleichtert worden.

%TODO besser formulieren
Ins jVR-Framework wurden viele häufig benutzten Grundfunktionen implementiert.
Dies dient dazu um die Produktivität zu steigern. Dadurch kommt der Entwickler
so gut wie nie in Kontakt mit reinen OpenGL-Befehlen.

\subsection{GLSL}

Eine weitere Besonderheit des jVR-Frameworks bietet die Unterstützung von
Shadern, die in der \emph{OpenGL Shader Language}, kurz GLSL geschrieben werden.
Shader sind kleine Programme die direkt auf der GPU ausgführt werden. Sie
ersetzen zudem die Fixed Function Pipeline von OpenGL.

GLSL besitzt eine C-ähnliche Syntax und besitzt zudem noch zusätzliche
Datentypen wie Vektoren und Matrizen. Vor der Verwendung müssen die Shader
compiliert werden. Dies bietet den Grafikkartenherstellern den Vorteil, den
Compiler für die eigene Hardware zu optimieren.

GLSL bietet außerdem die Möglichkeit ein besseres Beleuchtungsmodell zu
verwenden, als das von der Fixed Function Pipeline bereitgestellte. Seit Version
3.1 von OpenGL sind Fragment- und Vertex-Shader ein wichtiger Bestandteil der
Spezifikation und müssen zwingend implementiert werden. Optional kommen noch
Geometry- und Tesselation-Shader hinzu.

Dadurch lassen sich Oberflächeneffekte oder auch Effekte, wie Motion Blur und
Depth of Field erzeugen.

\subsection{JOGL}

Im jVR-Framework wird die \emph{Java Bindings for OpenGL} (JOGL) verwendet, um
OpenGL mit Java nutzen zu können. JOGL stellt eine Wrapperbibliothek dar, die die
OpenGL-Befehle über Javafunktionen ansteuern lässt.

Auf die native OpenGL API wird mit Hilfe des \emph{Java Native Interface} (JNI)
zugegriffen. Der native C-Code ist auf allen großen Systemen wie Windows, Mac OS
X und Linux verfügbar.

JOGL wurde von der Sun Microsystems Game Technology Group entwickelt. Es steht
als Open Source zur Verfügung und wird unter der BSD Lizenz angeboten. Es stellt
zudem eine Referenzimplementierung der Java Specification Request (JSR-231) dar.
JOGL wird möglicherweise in einer späteren Java-Version zu den
Standarbibliotheken mit aufgenommen.

In der Version 2 von JOGL wurden die GLProfile eingeführt. Diese ermöglichen es
dem Entwickler sich für ein OpenGL-Version zu entscheiden. Dadurch kann
bestimmt werden auf welchen Plattformen die erstellten Anwendungen laufen
und es werden zudem Kompatibilitätsprobleme vermieden.

Das jVR-Framework benutzt in diesem Fall das GL2GL3-Profil. Es vereint alle
Funktionen der Profile GL2 und GL3. Das Profil hat die Eigenschaft GL3 konform
zu sein. Es können daher GL3-Anwendungen entwickelt werden, die aber auch auf
Systemen lauffähig sind, die nur OpenGL 2 unterstützen.

% \begin{figure}[ht]
% 	\includegraphics[width=\linewidth]{img/glprofiles.png}
% 	\caption{Test 123}
% \end{figure}

\subsection{COLLADA}

Ein wichtiger Bestandteil des jVR-Frameworks stellt die Benutzung des
3D-Austausch-formats COLLADA dar. Dieses Format ist basiert auf der
Auszeichnungssprache XML. Es dient dazu wichtige Daten zwischen verschiedenen
3D-Programmen zu verwalten. Weiterhin ist als offener Standard definiert.

Eine COLLADA-Datei setzt sich aus mehreren Bereichen zusammen. Zum einen werden
die Geometrien beschrieben und zum anderen werden die verwendeten Texturen über
Pfade angesteuert. Weitere Bereiche sind Lichter, Materialien und Kameras.

Seit der Version 1.4 können auch physikalische Eigenschaften in COLLADA-Dateien
hinterlegt werden. Dabei können Oberflächeneigenschaften wie Reibung definiert
werden.

\subsection{Virtual Reality}

Zusätzlich bietet das jVR-Framework noch die Möglichkeit eine Art virtueller
Realität zu erzeugen. Dabei werden stereoskopische Bilder erzeugt, die durch
eine entsprechende Brille einen räumlichen Effekt simulieren. Dies wird
durch die Funktion des Multithreading geschafft.

Multithreading bedeutet mehrere Prozesse bzw. Aufgaben von der Engine
gleichzeitig durchführen zu lassen. Im Falle vom jVR-Framework lassen sich
mehrere Szenen gleichzeitig rendern. Es lassen sich zudem mehrere Anzeigegeräte
ansteuern. Dabei werden die zu erzeugenden Teilbilder parallel gerendert.

Um stereoskopische Bilder zu erzeugen werden 2 voneinander versetzte Kameras
aufgestellt und die Szene simultan aus Sicht der beiden Kameras gerendert. Bei
der Darstellung werden die 2 erzeugten Bilder übereinandergelegt. Mit der schon
erwähnten Brille werden die Bilder aus Sicht des Betrachters zusammengefügt. Es
entsteht ein 3dimensionaler Effekt.

Ein weiterer Teil der virtuellen Realität ist die Funktion des Headtrackings.
Dabei werden die Bewegung des Kopfes vom Betrachter aufgezeichnet und vom
Programm verarbeitet. Je nach Neigung bzw. Drehung des Kopfes wird die
betrachtete Szene angepasst, was dem Betrachter die Illusion vermittelt sich
tatsächlich in der Szene zu bewegen.

\chapter{Entwurf des Portal Cullings}

Alle zuvor diskutierten Themen stellen die Schwerpunkte der Arbeit dar. Die
Integration einer Portalfunktion in das jVR-Framework ist dabei als
Hauptschwerpunkt zu sehen.

Der Entwurf soll noch einmal die wichtigsten Konzepte wiedergeben. Zum einen
werden die verschiedenen Arten von Portalen beschrieben und erläutert. Hinzu
kommen die Verwendungen von virtuellen Kameras und deren Rolle beim erstellen
von Portalen.

\section{Portaltypen}

In Szenen gibt es mehrere Möglichkeiten in andere Räume zu schauen. Zum einen
kann der Betrachter direkt aus einem Fenster gucken oder sieht direkt durch die
offene Tür in den nächsten Raum. Zudem lässt sich durch den Blick in den Spiegel
der hintere Bereich des Raumes betrachten. All diese Bestandteile eines normalen
Raumes haben die Gemeinsamkeit, sich als Portal wiedergeben zu lassen.

Jeder dieser Portaltypen erhält seine eigene virtuelle Kamera, die die Szene aus
verschiedenen Blickwinkeln rendert und auf das jeweilige Portal projeziert wird.
Damit ist jeder von diesen Typen von der Klasse Portal abgeleitet.

\subsection{Türen}

Türen bieten die Besonderheit durchtreten werden zu können. Somit bieten sich
Türen als einziger Portaltyp an mehrere Räume miteinander zu verbinden. Türen
werden entweder direkt in einer Szene platziert und werden mit einem sich von
der Umgebung abhebenden Umriss versehen. Wenn eine Tür in die Szene platziert
wird, wird zudem ein virtuelle Kamera mitinstanziert um die Szene durch diese
gerendert werden kann.

Türen eignen sich auch um Culling durchzuführen. Wenn der Betrachter durch die
sieht, wird das Frustum auf den sichtbaren Umriss der Tür reduziert. Alle
Gegenstände, dessen Bounding Box innerhalb des View Frustums liegen werden
mitgerendert.

Da die Tür als Trenner der Räume (auch als Zellen bezeichnet) dient, kann
festgelegt werden welche 2 Räume miteinander verbunden sind. Dabei kann
ermittelt werden, welche Räume überhaupt nötig zum Rendern sind.

\subsection{Fenster}

Fenster verhalten sich ähnlich wie Türen, können aber nicht durchtreten werden.
Sie bieten nur die Möglichkeit in andere Räume bzw. außerhalb des Gebäudes zu
blicken. Ein Fenster kann trotzdem als verbindendes Glied für Räume genutzt
werden. Der Betrachter sieht einen anderen Raum, aber kann diesen nicht
erreichen.

Fenster bieten ebenfalls wie Türen ein Culling an. Beim Betrachten werden wieder
nur jeweils die Objekte dessen BB innerhalb des View Frustums liegen gerendert.
Ähnlich den Türen kann über ein Fenster ermittelt werden, welcher Raum mit einem
anderen verbunden ist.

\subsection{Spiegel}

Ein besonderer Portaltyp ist der Spiegel. Er kann genau wie das Fenster nicht
durchtreten werden. Außerdem dient er nicht dazu Räum miteinander zu verbinden.
Der Spiegel bietet die Funktion den Sichtbereich des jeweiligen Betrachters aus
Sicht des Spiegel zu reflektieren und zu projezieren. 

Dabei dient die Spiegeloberfläche als Reflexionsebene an der der Standpunkt des
Betrachters gespiegelt wird und in Form einer virtuellen Kamera wiedergegeben
wird. Diese virtuelle Kamera rendert mit negiertem Seitenverhältnis die Szene
aus Sicht der Spiegelfläche und negativer Skalierung.

\subsection{Teleporter}

Der Teleporter ist eine Abwandlung der Tür. Im Gegensatz zur Tür, verbindet der
Teleporter keine Räume miteinander. Der Teleporter dient als eine Art
Schnellreisesystem. Er verbindet 2 Türen miteinander, die im Raum sehr weit weg
voneinander entfernt liegen. Sie werden über die Klasse \texttt{PortalConnector}
verbunden.

Wie die Tür erhält jeder Teleporter eine virtuelle Kamera. Diese Kamera werden
relativ zur Position der Kamera des Betrachters zum Teleporter auf der
Gegenseite ausgerichtet. Je nach Bewegung des Betrachters bewegt sich auch die
virtuelle Kamera.

\section{Virtuelle Kameras}

Die virtuellen Kameras sind ein wichtiger Bestandteil der Portale. Sie stellen
die Szene aus sicht des Portals dar. Für jede virtuelle Kamera wird ein
\texttt{FrameBufferObjekt} angelegt, welches erst im zum Schluss auf das
jeweilige Portal projeziert wird.

Die Szene wird im Falle eines Portals aus Sicht der virtuellen Kamera gerendert.
Jedes Portal besitzt eine eigene virtuelle Kamera. Diese kann direkt
über das jeweilige Portal angesprochen werden. Somit lassen sich Eigenschaften,
wie Sichtbereich oder die Transformation bestimmen.

\section{Zellen}

Zellen stellen in sich abgeschlossene Räume dar. Sie sind \texttt{GroupNodes}
und können daher weitere Szeneknoten enthalten. Zellen können über Türen
miteinander verbunden werden. Jede Zelle wird durch 4 Wände definiert, wobei die
Breite, Länge und Höhe einer Zelle variieren kann. Innerhalb einer Zelle
befindet sich zudem \texttt{PointLightNode}, um innerhalb positionierte Objekte
richtig darstellen zu können. Eine Zelle lässt sich farblich anpassen, oder aber
mit einer Textur versehen.

\chapter{Praktische Umsetzung}

\section{Zu verwendende Algorithmen}

\section{Strukturierung}

\section{Implementierung}

\subsection{Verwendete Pattern}

\subsection{Codebeispiele / Erläuterungen}

\section{Mögliche Problemfälle und Optimierungen}

Natürlich treten auch Probleme innerhalb der Implementierung auf, die
berücksichtigt werden müssen. Mögliche auftretende Problem werden genauer
beleuchtet und mit entsprechenden Gegenmaßnahmen gelöst.

\subsection{Schatten}

Dadurch, dass Objekte im Portal Culling nicht gerendert werden kann es auch zu
Problemen bei der Darstellung der Szene kommen. Wenn z.B. ein Objekt innerhalb
des Raumes, der durch ein Portal betrachtet wird einen Schatten wirft, aber in
diesem Moment das Objekt nicht sichtbar ist und daher nicht gerendert wird, kann
somit auch der Schatten nicht erzeugt und nicht in der Szene angezeigt werden.
Dies fährt zu einem plötzlichen aufblitzen von Schatten, was dem natürlichem
Verständnis vom Schattenwurf widerspricht.

\subsection{Reflexionen}

Ein weiteres Problem, welches Auftreten kann sind mögliche Reflexionen innerhalb
des Raumes. Falls in dem betrachteten Raum ein Spiegel steht und die Objekte
zwar nicht direkt durch die Tür bzw. das Fenster sichtbar sind, aber indirekt
durch einen Spiegel betrachtet werden können. Es werden alle Objekte, die nicht
direkt sichtbar wären ebenso wenig im Spiegel zu sehen. Ebenso verhält es sich
mit möglichen anderen Portalen, die ebenfalls nur durch einen Blick um die Ecke
sichtbar würden.

\subsection{Lösungsansätze}

\chapter{Ergebnisse und Bewertung}

\chapter{Zusammenfassung und Ausblick}

\bibliography{lit}
\bibliographystyle{apalike}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}

\end{document}

